%---------------------------------------------------
% Nombre: capitulo2.tex  
% 
% Texto del capítulo 2
%---------------------------------------------------

\chapter{Planificación del proyecto}

Planificar un proyecto informático de manera correcta ser el factor crucial que determine el éxito, o en su defecto el fracaso  del mismo. La necesidad de una correcta planificación se acentúa más en proyectos enmarcados dentro de ámbito del Big Data. Estos proyectos son verdaderas obras de ingeniería teniendo en cuenta la necesidad de equipos, recursos humanos, software, variables (tiempo de computo, memoria, costes) que pueden implicar. Es por ello, que en este capítulo haremos un pequeño resumen de la planificación del proyecto, aportando una visión general de los recursos implicados. 

\section{Gestión de recursos}

En la primera sección de este capítulo, se hará un repaso por los principales recursos implicados pudiendo estos ser categorizados como personal, hardware y software, los cuales son a su vez los tres pilares clave de un proyecto de tecnologías de la información y la comunicación. 

\subsection{Personal}
\label{personal}
El personal a cargo del proyecto, consta principalmente del autor José Ángel Díaz García, encargado de desarrollar todas las partes del mismo mediante la supervisión de los tutores. Por otro lado se ha contado con cierta asesoría y ayuda de miembros del equipo de investigación de bases de datos y sistemas de información inteligentes. 

\subsection{Hardware}

Para elaboración de memorias, notas, artículos así como para los procesos de datos menos complejos se ha utilizado el sistema descrito en la tabla \ref{ord_personal}. Por otro lado, todo el proceso basado en Big Data se ha llevado a cabo en el cluster de procesado de datos del grupo de investigación, este cluster está formado por 4 maquinas cuyas especificaciones pueden verse en la tabla ref{cluster}.

\label{hardware}
\begin{table}[H]
	\begin{center}
		\begin{tabular}{cc} \toprule
		Elemento & Características \\ \midrule
		Procesador & 2,6 GHz Intel Core i5 \\
		Memoria Ram &  8 GB 1600 MHz DDR3 \\
		Disco duro & SATA SSD de 120 GB\\ \bottomrule
		\end{tabular}
	\end{center}
\caption{Especificaciones técnicas de la máquina personal usada.}
\label{ord_personal}
\end{table}


\begin{table}[H]
	\begin{center}
		\begin{tabular}{cc} \toprule
		Elemento & Características \\ \midrule
		Procesador & Intel Xeon E5-2665 \\
		Memoria Ram &  32 GB  \\
		Nucleos & 8 \\ \bottomrule
		\end{tabular}
	\end{center}
\caption{Especificaciones técnicas del cluster.}
\label{cluster}
\end{table}


\subsection{Software}

El software utilizado es en su práctica totalidad software libre, siendo el restante software propietario cuyas licencias vienen incluidas en el sistema operativo de la máquina usada siendo este OS X . El software usado es:


\begin{itemize}
\item \textbf{TeXShop}: Procesador de textos basado en Latex usado para elaborar la documentación del presente proyecto. 
\item \textbf{Twitter}: Red social de microblogging. 
\item \textbf{MongoDB}: Base datos noSQL usada como almacén persistente de los datos.
\item \textbf{RStudio}: Entorno de Desarrollo en R donde se ha realizado la mayor parte del proceso del proyecto. 
\item \textbf{RSpark}: Pasarela entre R y Spark que permite usar funciones de Spark de manera nativa en R.
 \item \textbf{Spark}:  Entorno  de computación en cluster usado para elaborar los procesos de Big Data más complejos. 
\item \textbf{Git}: Sistema utilizado para el control de versiones. 
\end{itemize}


\section{Planificación temporal}

En este punto estudiaremos la planificación temporal seguida, así como los pequeños hitos que en cada una de las etapas se fueron consiguiendo y la duración de las mismas. 

\begin{enumerate}
\item \textbf{Obtención de información y estudio del tema}: La primera parte del proyecto consistió en la obtención de información acerca de la minería de opiniones y de las reglas de asociación así como de la aplicación de estas en el ámbito de la minería de redes sociales y más concretamente en Twitter. En este primer proceso de recopilación de información también se estudiaron temas más genéricos dentro del Big Data y la minería de datos con el fin de tener una visión global de las herramientas y técnicas a estudiar y usar en el problema. Esta etapa aunque ha sido continua, tuvo especial importancia desde mediados de noviembre de 2016 a finales de diciembre de ese mismo año. 

\item \textbf{Estudio del estado del arte}: Tras obtener buena cantidad de información y comprender el problema a resolver, se realizó un estudio exhaustivo del estado del arte de la materia así como a comenzar a desarrollar los primeros capítulos de la memoria en cuestión. Esta etapa tuvo lugar desde finales de diciembre de 2016 hasta finalizar el proyecto debido a que se ha realizado un estudio continuo de los nuevos trabajos que iban apareciendo sobre la temática. 
 
 \item \textbf{Selección de herramientas}: Una vez fijado Twitter como medio objetivo, se llevó a cabo una investigación sobre las herramientas más oportunas para la obtención de los tuits de la red social. Esta etapa tuvo lugar entre final de junio y principio de julio de 2017. 
 
\item \textbf{Obtención del dataset}: Para poder comenzar a hacer pruebas y desarrollar el sistema basado en reglas, una vez elegida la herramienta, se comenzó a obtener datos de la red social durante unos días ininterrumpidamente para tener un conjunto de entrenamiento suficiente. Esta tarea tomo lugar a mediados de julio de 2017. 

\item \textbf{Carga y preprocesado de los datos}: Una vez obtenidos los datos y almacenados en MongoDB se hizo necesaria su carga y limpieza, esta tarea no es trivial ya que necesitó de técnicas de procesado del lenguaje natural y aplicaciones de Big Data para poder trabajar con un volumen de datos muy elevado en una máquina estándar como es el caso. Esta tarea fue llevada a cabo entre los meses de julio y octubre de 2017. 

\item \textbf{Limpieza de datos}: Dado que partimos de un problema no supervisado, donde los datos carecían de filtrado alguno, esta fue una de las etapas que más tiempo tomó. Tras la aplicación de técnicas básicas de limpieza en minería de textos, se aplicaron técnicas experimentales de procesamiento del lenguaje natural para filtrar los datos y poder poner el foco del problema en aquel subconjunto de datos que hace referencia a personas. Dado el volumen de datos esta etapa precisó el uso de un cluster de procesado así como de técnicas de programación paralela y concurrente que podríamos enmarcar como Big Data. Esta tarea fue llevada a cabo entre octubre y diciembre de 2017.

\item \textbf{Análisis exploratorio de datos}: Sobre el dataset final, se han realizado gráficos y estudios estadísticos básicos con el fin de conocer y entender mejor la naturaleza de los mismos. Esta tarea fue llevada a cabo durante el mes de diciembre de 2017. 

\item \textbf{Análisis de sentimientos}: Sobre los datos, se aplicaron técnicas de análisis de sentimientos para poder realizar gráficos que nos ayudaran a discernir qué palabras o expresiones estaban relacionadas en nuestro dataset con sentimientos para en el paso de obtención de reglas de asociación poder polarizar en cierta medida las mismas, o tener al menos, otro enfoque subjetivo de éstas, pudiendo así desambiguar en cierta medida las mismas. Esta tarea fue llevada a cabo durante el mes de diciembre de 2017. 

\item \textbf{Reglas de asociación y experimentación}: Con los datos limpios y estudiados, se obtienen un conjunto de reglas de asociación sobre la temática y se experimenta sobre el mismo obteniendo distintos conjuntos en función de itemsets frecuentes, así como de la variación de los parámetros de confianza y soporte en las reglas. Esta tarea comprendió los meses de diciembre de 2017 y enero de 2018. 

\item \textbf{Elaboración de la memoria}: La memoria ha constado de una elaboración continua, ya que continuamente se han ido añadiendo y refinando capítulos en función de cómo se avanzaba en el proceso de desarrollo y experimentación. Los meses que ha comprendido su elaboración, han sido por tanto desde primeros de febrero de 2017 hasta enero de 2018. 

\end{enumerate}

\section{Requisitos del sistema final}

Dado que el sistema final estará basada en una pequeña aplicación web en este punto veremos un pequeño análisis de requisitos del mismo. 

	\subsection{Requisitos funcionales}
		\begin{itemize}
			\item \textbf{RF1}: El sistema permitirá al usuario final elegir sobre que términos desea obtener información. 
			\item \textbf{RF2}: El sistema mostrará al usuario final de una manera amigable mediante tag clouds y tablas la información sobre los términos que cubran su necesidad de información.
			\item \textbf{RF3}: El sistema permitirá refinar la búsqueda en función de diversos factores, como por ejemplo frecuencias. 
			\item \textbf{RF4}: El sistema actualizará de manera automática los métodos de visualización en función de los posibles patrones de refinado introducidos por el usuario.
			\item \textbf{RF5}: El sistema permitirá también al usuario ver los sentimientos asociados con términos, así como la polaridad de los tweets o las reglas de asociación asociadas a los tweets.
		\end{itemize}
	
\subsection{Requisitos no funcionales}
	\begin{itemize}
		\item \textbf{RNF1}: El sistema debe trabajar con corpus de datos de varios GB sin problema. 
		\item \textbf{RNF2}: El sistema debe poder crear los recursos de visualización para  un determinado termino en menos de 30 segundos. 
		\item \textbf{RNF3}: El sistema debe poder operar de manera concurrente con hasta 10 usuarios. 
	\end{itemize}

\section{Costes}

Tras el análisis de los recursos empleados y la planificación temporal seguida, es menester estimar los costes del proyecto en el supuesto caso de su implantación en una empresa o grupo de investigación. Esta estimación de costes está realizada en función de dos verticales, los gastos de personal y los gastos de ejecución.

\subsubsection{Personal}

Como hemos descrito en la sección \ref{personal} el personal radica en un solo investigador y la dedicación total atendiendo a la carga lectiva del proyecto final de máster, estaría en torno a los 3 meses a jornada completa. Teniendo en cuenta una estimación de unos 2000 euros brutos al mes tendríamos un total de 6000 euros en gastos de personal. 

\subsubsection{Ejecución}

En esta categoría encontramos los gastos de adquisición del material inventariable así como los gastos del material fungible. Como inventariable, tenemos los equipos descritos en la tabla \ref{hardware}, es decir, el equipo personal y el cluster de procesado cuyo coste en función del período de amortización (precio por uso dividido entre tiempo de amortización) puede verse en la tabla \ref{costeshardware}.

\begin{table}[H]
	\begin{center}
		\begin{tabular}{c c c c c} \toprule
		Unidad & Precio & Periodo Amortización & Duración proyecto & Total \\ \midrule
		Mac pro 2,6GHz & 1300 & 2 años & 1,5 meses & 81,25 \\
		Intel Core i5 & & & \\
		Cluster & 6000 & 6 & 1mes & 120\\ \bottomrule
		\end{tabular}
	\end{center}
\caption{Detalle de costes inventariables.}
\label{costeshardware}
\end{table}

Si atendemos a los costes fungibles, aquellos cuyo inventariado es menos relevante como por ejemplo el material de oficina podríamos estimarlo en unos 100 euros. 

\subsubsection{Resumen de gastos}

En función a los cálculos estimados de costes realizados en esta sección, en la tabla  \ref{resumen} podemos ver el total de los gastos que podrían derivarse del proyecto. 

\begin{table}[H]
	\begin{center}
		\begin{tabular}{c c } \toprule
		Gastos elegibles & Total  \\ \midrule
		Personal & 6000  \\
		Costes inventariables & 201,25  \\
		Costes fungibles & 100 \\
		\textbf{TOTAL} & 6301,25 \\ \bottomrule
		\end{tabular}
	\end{center}
\caption{Resumen final de costes.}
\label{resumen}
\end{table}


\pagebreak

\clearpage
%---------------------------------------------------